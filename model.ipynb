{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/yRSFEIY10bpnjvxDEStD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7a9OJMNDmr1_","executionInfo":{"status":"ok","timestamp":1660354663498,"user_tz":300,"elapsed":16462,"user":{"displayName":"John Li","userId":"07983087676873063182"}},"outputId":"d2d8d120-dfc1-4e33-9f6c-3078e9a45661"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n"]},{"cell_type":"code","source":["import os\n","os.chdir('drive/MyDrive/CycleGANs')"],"metadata":{"id":"dKTX3RCEn7tK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from random import random\n","from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy import asarray\n","from numpy.random import randint\n","\n","import numpy as np\n","import os\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","\n","import matplotlib.pyplot as plt\n","import torchvision.utils as vutils\n","import torch.autograd as autograd\n","torch.set_printoptions(threshold=5000)\n","from matplotlib import pyplot\n","from statistics import mean"],"metadata":{"id":"k9fDtYTknRMw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Loaders"],"metadata":{"id":"EFpvyJOwAIzR"}},{"cell_type":"code","source":["batch_size=5\n","workers=2\n","image_size=(256,256)\n","\n","# load training set of monet paintings\n","dataset_monet_train = dset.ImageFolder(root=\"dataset/trainMonet\",\n","                                       transform=transforms.Compose([transforms.Resize(image_size),\n","                                                                     transforms.CenterCrop(image_size),\n","                                                                     transforms.ToTensor(),\n","                                                                     transforms.Normalize((0, 0, 0), (1, 1, 1)),]))\n","dataloader_monet_train = torch.utils.data.DataLoader(dataset_monet_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n","\n","# load training set of real pictures\n","dataset_picture_train = dset.ImageFolder(root=\"dataset/trainPicture\",\n","                                         transform=transforms.Compose([transforms.Resize(image_size),\n","                                                                       transforms.CenterCrop(image_size),\n","                                                                       transforms.ToTensor(),\n","                                                                       transforms.Normalize((0, 0, 0), (1, 1, 1)),]))\n","dataloader_picture_train = torch.utils.data.DataLoader(dataset_picture_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n","\n","# load test set of monet paintings\n","dataset_monet_test = dset.ImageFolder(root=\"dataset/testMonet\",\n","                                      transform=transforms.Compose([transforms.Resize(image_size),\n","                                                                    transforms.CenterCrop(image_size),\n","                                                                    transforms.ToTensor(),\n","                                                                    transforms.Normalize((0, 0, 0), (1, 1, 1)),]))\n","dataloader_monet_test = torch.utils.data.DataLoader(dataset_monet_test, batch_size=batch_size, shuffle=True, num_workers=workers)\n","\n","# load test set of picture paintings\n","dataset_picture_test = dset.ImageFolder(root=\"dataset/testPicture\",\n","                                      transform=transforms.Compose([transforms.Resize(image_size),\n","                                                                    transforms.CenterCrop(image_size),\n","                                                                    transforms.ToTensor(),\n","                                                                    transforms.Normalize((0, 0, 0), (1, 1, 1)),]))\n","dataloader_picture_test = torch.utils.data.DataLoader(dataset_picture_test, batch_size=batch_size, shuffle=True, num_workers=workers)"],"metadata":{"id":"iQ7ZSQJAqOGP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Architectures"],"metadata":{"id":"_inoN_2HrWJW"}},{"cell_type":"markdown","source":["Discriminator"],"metadata":{"id":"5R6wIEwRrsGw"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.LeakyReLU = nn.LeakyReLU(0.2)\n","\n","        #Convolutional Layers\n","        self.c3_64 = nn.Conv2d(3, 64, 4, stride=2, padding=1)\n","        self.c64_128 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n","        self.c128_256 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n","        self.c256_512 = nn.Conv2d(256, 512, 4, stride=2, padding=1)\n","        self.c512_512 = nn.Conv2d(512, 512, 4, padding=1)\n","        self.c512_1 = nn.Conv2d(512, 1, 4, padding=1)\n","\n","        #Instance Normalization Layers\n","        self.i_128 = nn.InstanceNorm2d(128)\n","        self.i_256 = nn.InstanceNorm2d(256)\n","        self.i_512_1 = nn.InstanceNorm2d(512)\n","        self.i_512_2 = nn.InstanceNorm2d(512)\n","\n","        #Linear (for Wasserstein GANs)\n","        #self.lin = nn.Linear()\n","\n","    def forward(self, x):\n","        #x: image of size 3x256x256\n","\n","        #x1: 64x128x128\n","        x1 = self.LeakyReLU(self.c3_64(x))\n","\n","        #x2: 128x64x64\n","        x2 = self.LeakyReLU(self.i_128(self.c64_128(x1)))\n","\n","        #x3: 256x32x32\n","        x3 = self.LeakyReLU(self.i_256(self.c128_256(x2)))\n","\n","        #x4: 512x16x16\n","        x4 = self.LeakyReLU(self.i_512_1(self.c256_512(x3)))\n","\n","        #x5: 512x16x16\n","        x5 = self.LeakyReLU(self.i_512_2(self.c512_512(x4)))\n","\n","        # out: 1 x 16 x 16\n","        # fine grained-discrimination\n","        out = self.c512_1(x5)\n","\n","        return out"],"metadata":{"id":"Nd61tHZCrvTU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generator"],"metadata":{"id":"KjV8hG8j40Pk"}},{"cell_type":"code","source":["class ResNetBlock(nn.Module):\n","    def __init__(self):\n","        super(ResNetBlock, self).__init__()\n","        self.layers=nn.Sequential(nn.Conv2d(256, 256, 3, padding='same'),\n","                                  nn.InstanceNorm2d(256),\n","                                  nn.ReLU(),\n","                                  nn.Conv2d(256, 256, 3, padding='same'))\n","        # Concatenate before second instance normalization layer\n","        self.i_256=nn.InstanceNorm2d(256)\n","        self.ReLU=nn.ReLU()\n","\n","    def forward(self, x):\n","        cat=self.layers(x) + x\n","        normed=self.i_256(cat)\n","        out=self.ReLU(normed)\n","        return out\n","\n","def genBlockSequence(num_blocks=8):\n","    if num_blocks == 0:\n","        return nn.Identity\n","    ls = [ResNetBlock() for i in range(num_blocks)]\n","    return ls\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, num_ResNetBlocks=8):\n","        super(Generator, self).__init__()\n","\n","        self.encoder = nn.Sequential(nn.ReflectionPad2d(3),\n","                                     nn.Conv2d(3, 64, 7, stride=1, padding=0), nn.InstanceNorm2d(64), nn.ReLU(),\n","                                     nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(),\n","                                     nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.InstanceNorm2d(256), nn.ReLU())\n","\n","        self.residual_network_blocks = nn.Sequential(*genBlockSequence(num_ResNetBlocks))\n","\n","        self.decoder = nn.Sequential(nn.ConvTranspose2d(256, 512, 3, 1, 1), nn.PixelShuffle(2), nn.InstanceNorm2d(128), nn.ReLU(),\n","                                     nn.ConvTranspose2d(128, 256, 3, 1, 1), nn.PixelShuffle(2), nn.InstanceNorm2d(64), nn.ReLU(),\n","                                     nn.ReflectionPad2d(3),\n","                                     nn.Conv2d(64, 3, 7, 1, 0),\n","                                     nn.Tanh())\n","\n","    def forward(self, x):\n","\n","        #x: image of size 3x256x256\n","        encoded_image = self.encoder(x)\n","        mapped = self.residual_network_blocks(encoded_image)\n","        decoded = self.decoder(mapped)\n","\n","        return decoded\n"],"metadata":{"id":"u1XqdW8m41yi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loss Functions"],"metadata":{"id":"XhjCk4bsAd7Y"}},{"cell_type":"code","source":["def discriminator_loss(real_score, fake_score):\n","    return torch.mean(fake_score**2)+torch.mean((real_score-1)**2)\n","\n","def generator_loss(disc_results):\n","    return torch.mean((1-disc_results)**2)"],"metadata":{"id":"grSVxT4xAi4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_grad_norm_on_interpolates(D, real_images, gen_images, batch_size=5):\n","    alpha = torch.rand(batch_size, 1, 1, 1).expand(real_images.size()).cuda()\n","\n","    interpolates = alpha * real_images + (1-alpha) * gen_images\n","    interpolates = autograd.Variable(interpolates, requires_grad=True)\n","\n","    interpolates_D_results = D(interpolates)\n","\n","    gradients = autograd.grad(outputs=interpolates_D_results, inputs=interpolates,\n","                            grad_outputs=torch.ones(interpolates_D_results.size()).cuda(),\n","                            create_graph=True, retain_graph=True, only_inputs=True)[0]\n","\n","    grad_norm_on_interpolates = torch.mean(\n","                                    ((torch.linalg.norm(gradients, 2, dim=1) - 1) ** 2))\n","\n","    del interpolates, gradients, alpha, real_images, gen_images\n","    return grad_norm_on_interpolates"],"metadata":{"id":"TjAYW8l2jYqA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"6q_miHO-j662"}},{"cell_type":"code","source":["#initialize dictionary of losses\n","def reset_losses():\n","    LossesInEpoch = {\n","        \"Total_Gen\": [],\n","        \"D_Monet\" : [],\n","        \"D_Picture\" : [],\n","        \"Gen_Monet2Picture\":[], #loss computed by the discriminator\n","        \"Gen_Picture2Monet\":[],\n","        \"Cycle_Monet\":[],\n","        \"Cycle_Picture\":[],\n","        \"Identity_Picture2Monet\":[],\n","        \"Identity_Monet2Picture\":[]\n","    }\n","    return LossesInEpoch\n","\n","def avg_losses(LossesInEpoch):\n","    tg = LossesInEpoch[\"Total_Gen\"]\n","    da = LossesInEpoch[\"D_Monet\"]\n","    df = LossesInEpoch[\"D_Picture\"]\n","    gp = LossesInEpoch[\"Gen_Monet2Picture\"]\n","    gm = LossesInEpoch[\"Gen_Picture2Monet\"]\n","    cm = LossesInEpoch[\"Cycle_Monet\"]\n","    cp = LossesInEpoch[\"Cycle_Picture\"]\n","    im= LossesInEpoch[\"Identity_Picture2Monet\"]\n","    ip = LossesInEpoch[\"Identity_Monet2Picture\"]\n","\n","    return sum(tg)/len(tg), sum(da)/len(da), sum(df)/len(df), sum(gp)/len(gp), sum(gm)/len(gm), sum(cm)/len(cm), sum(cp)/len(cp), sum(im)/len(im),sum(ip)/len(ip)\n"],"metadata":{"id":"8zRpvU1yj-RC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.transforms.functional import to_grayscale\n","def train(dataloader_picture_train, dataloader_monet_train,\n","        dataloader_picture_test, dataloader_monet_test,\n","        G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture,\n","        optimizer_D_Monet, optimizer_D_Picture, optimizer_G_Monet2Picture, optimizer_G_Picture2Monet,\n","        start_epoch, max_num_epochs=200):\n","\n","\n","    # Move generators and discriminators to GPU\n","    G_Monet2Picture = G_Monet2Picture.cuda()\n","    G_Picture2Monet = G_Picture2Monet.cuda()\n","    D_Monet = D_Monet.cuda()\n","    D_Picture = D_Picture.cuda()\n","    #Set the criterion for cycle and identity loss\n","    criterion = torch.nn.L1Loss()\n","\n","\n","    # Dicionary of all losses to keep track of progress\n","    LossesInEpoch = reset_losses()\n","    LossesAcrossEpochs = reset_losses()\n","\n","    #Training Loop\n","    for epoch in range(start_epoch, max_num_epochs):\n","\n","        #0 iterations\n","        iters = 0\n","\n","        # Iterate through batches\n","        for t, (data_picture, data_monet) in enumerate(zip(dataloader_picture_train, dataloader_monet_train),0):\n","\n","            # Move data to GPU\n","            picture_real = data_picture[0].cuda()\n","            monet_real = data_monet[0].cuda()\n","\n","            # Forward passes\n","            picture_fake = G_Monet2Picture(monet_real)\n","            monet_reconstructed = G_Picture2Monet(picture_fake)     #for cycle loss\n","            monet_fake = G_Picture2Monet(picture_real)\n","            picture_reconstructed = G_Monet2Picture(monet_fake)        #for cycle loss\n","\n","            # Discriminator Anime, compute on generated images randomly sampled from cache\n","            # Every 3 iterations\n","            optimizer_D_Monet.zero_grad()\n","            if (iters > 0 or epoch > start_epoch) and iters % 3 == 0:\n","                #Sample non-contiguous block\n","                idx = torch.randint(0, cache_monet_fake.size(0), (5,))              #revisit here\n","                samples = cache_monet_fake[idx]\n","\n","                Disc_loss_Monet = discriminator_loss(D_Monet(monet_real), D_Monet(samples.detach()))        #revisit here\n","\n","\n","                LossesInEpoch[\"D_Monet\"].append(Disc_loss_Monet.item())\n","\n","            else:\n","                #Calculate Discriminator loss\n","                Disc_loss_Monet = discriminator_loss(D_Monet(monet_real), D_Monet(monet_fake.detach()))\n","                LossesInEpoch[\"D_Monet\"].append(Disc_loss_Monet.item())\n","\n","\n","            Disc_loss_Monet.backward()\n","            optimizer_D_Monet.step()\n","\n","            # Discriminator Face, compute on generated images randomly sampled from cache\n","            # Every 3 Iterations\n","            optimizer_D_Picture.zero_grad()\n","\n","            if (iters > 0 or epoch > start_epoch) and iters % 3 == 0:\n","                #Sample non-contiguous block !Change\n","                idx = torch.randint(0, cache_picture_fake.size(0), (5,))\n","                samples = cache_picture_fake[idx]\n","\n","                Disc_loss_Picture = discriminator_loss(D_Picture(picture_real), D_Picture(samples.detach()))\n","                LossesInEpoch[\"D_Picture\"].append(Disc_loss_Picture.item())\n","\n","            else:\n","                Disc_loss_Picture = discriminator_loss(D_Picture(picture_real), D_Picture(picture_fake.detach()))\n","\n","                LossesInEpoch[\"D_Picture\"].append(Disc_loss_Picture.item())\n","\n","\n","            Disc_loss_Picture.backward()\n","            optimizer_D_Picture.step()\n","\n","            # Generator Losses:\n","            optimizer_G_Picture2Monet.zero_grad()\n","            optimizer_G_Monet2Picture.zero_grad()\n","\n","            # Discriminator based generators Losses\n","            Gen_loss_Monet2Picture = generator_loss(D_Picture(picture_fake))\n","            Gen_loss_Picture2Monet = generator_loss(D_Monet(monet_fake))\n","\n","            # Cycle Consistency both use the two generators\n","            Cycle_loss_Monet = criterion(monet_reconstructed, monet_real)*10\n","            Cycle_loss_Picture = criterion(picture_reconstructed, picture_real)*10\n","\n","            # Identity loss\n","            Id_loss_Picture2Monet = criterion(G_Picture2Monet(monet_real), monet_real)*5\n","            Id_loss_Monet2Picture = criterion(G_Monet2Picture(picture_real), picture_real)*5\n","\n","            # Total losses for generators to back-prop through\n","            Total_Loss = Gen_loss_Monet2Picture + Gen_loss_Picture2Monet + \\\n","                    Cycle_loss_Monet + Cycle_loss_Picture + \\\n","                    Id_loss_Picture2Monet + Id_loss_Monet2Picture\n","\n","            LossesInEpoch[\"Total_Gen\"].append(Total_Loss)\n","            LossesInEpoch[\"D_Monet\"].append(Disc_loss_Monet)\n","            LossesInEpoch[\"D_Picture\"].append(Disc_loss_Picture)\n","            LossesInEpoch[\"Gen_Monet2Picture\"].append(Gen_loss_Monet2Picture)\n","            LossesInEpoch[\"Gen_Picture2Monet\"].append(Gen_loss_Picture2Monet)\n","            LossesInEpoch[\"Cycle_Monet\"].append(Cycle_loss_Monet)\n","            LossesInEpoch[\"Cycle_Picture\"].append(Cycle_loss_Picture)\n","            LossesInEpoch[\"Identity_Picture2Monet\"].append(Id_loss_Picture2Monet)\n","            LossesInEpoch[\"Identity_Monet2Picture\"].append(Id_loss_Monet2Picture)\n","\n","            #Backpropogate\n","            Total_Loss.backward()\n","\n","            # Optimisation step\n","            optimizer_G_Picture2Monet.step()\n","            optimizer_G_Monet2Picture.step()\n","\n","            # Define the fake caches\n","            #If caches are empty, clone most recent inputs\n","            #If cache is not full, add inputs to cache\n","            #If cache is full, replace random elements of cache with most recent input\n","            if(epoch == start_epoch and iters == 0):\n","                cache_picture_fake = picture_fake.clone()\n","                cache_monet_fake = monet_fake.clone()\n","            elif (cache_picture_fake.shape[0] >= batch_size * 5 and\n","                    picture_fake.shape[0] >= batch_size * 5):\n","\n","                #Randomly sampling is different, so this  can be a contiguous block\n","                rand_int = randint(5, 24)\n","                cache_picture_fake[rand_int-5:rand_int] = picture_fake.clone()\n","                cache_monet_fake[rand_int-5:rand_int] = monet_fake.clone()\n","\n","            elif(cache_picture_fake.shape[0]< 25):\n","                cache_picture_fake = torch.cat((picture_fake.clone(), cache_picture_fake))\n","                cache_monet_fake = torch.cat((monet_fake.clone(), cache_monet_fake))\n","\n","            #Increment Iterations\n","            iters += 1\n","\n","            # Release GPU memory\n","            del data_picture, data_monet, monet_real, picture_real, monet_fake, picture_fake #, interpolates\n","\n","            # Print intermediate results\n","            if iters % 50 == 0:\n","                print('Epoch %d \\tLosses: \\tGenTotal: %.4f\\tGen_Monet2Picture: %.4f\\tGen_Picture2Monet: %.4f\\tCycle_Monet: %.4f\\tCycle_Picture: %.4f\\tID_Picture2Monet: %.4f\\tID_Monet2Picture: %.4f\\tDisc_Monet: %.4f\\tDisc_Picture: %.4f'\n","                            % (epoch,\n","                                Total_Loss,\n","                                Gen_loss_Monet2Picture, Gen_loss_Picture2Monet,\n","                                Cycle_loss_Monet, Cycle_loss_Picture,\n","                                Id_loss_Picture2Monet, Id_loss_Monet2Picture,\n","                                Disc_loss_Monet.item(), Disc_loss_Picture.item()))\n","\n","        #Save Models\n","        #If we save all the models, we take up 400 gigabytes. Save the newest, and\n","        #Save one at certain checkpoints\n","\n","        if epoch in [15, 25, 35, 45, 50, 60, 70, 75, 85, 95, 100]:\n","            save_models(G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture, str(epoch))\n","        else:\n","            save_models(G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture, 'newest')\n","        # if(epoch == 15):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"15\")\n","        # elif(epoch==25):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"25\")\n","        # elif(epoch==35):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"35\")\n","        # elif(epoch==45):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"45\")\n","        # elif(epoch==50):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"50\")\n","        # elif(epoch==60):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"60\")\n","        # elif(epoch==70):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"70\")\n","        # elif(epoch==75):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"75\")\n","        # elif(epoch==85):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"85\")\n","        # elif(epoch==95):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"95\")\n","        # elif(epoch==100):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"100\")\n","        # elif(epoch==150):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"150\")\n","        # elif(epoch==199):\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"199\")\n","        # else:\n","        #     save_models(G_Anime2Face, G_Face2Anime, D_Anime, D_Face, \"newest\")\n","\n","\n","        # Test and plot the images\n","        #if epoch % 3 == 0:\n","        plot_images_test(dataloader_monet_test, dataloader_picture_test)\n","\n","        #Compute Average Loss Across The Epoch for each of the loss measurments\n","        l1, l2, l3, l4, l5, l6, l7, l8, l9 = avg_losses(LossesInEpoch)\n","\n","        LossesAcrossEpochs[\"Total_Gen\"].append(l1)\n","        LossesAcrossEpochs[\"D_Monet\"].append(l2)\n","        LossesAcrossEpochs[\"D_Picture\"].append(l3)\n","        LossesAcrossEpochs[\"Gen_Monet2Picture\"].append(l4)\n","        LossesAcrossEpochs[\"Gen_Picture2Monet\"].append(l5)\n","        LossesAcrossEpochs[\"Cycle_Monet\"].append(l6)\n","        LossesAcrossEpochs[\"Cycle_Picture\"].append(l7)\n","        LossesAcrossEpochs[\"Identity_Picture2Monet\"].append(l8)\n","        LossesAcrossEpochs[\"Identity_Monet2Picture\"].append(l9)\n","        LossesInEpoch = reset_losses()\n","\n","\n","    return LossesAcrossEpochs"],"metadata":{"id":"L1v41pnJkzgc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Save and Load Models"],"metadata":{"id":"0Ay45_h755Gi"}},{"cell_type":"code","source":["def save_models(generator1, generator2, discriminator1, discriminator2, name):\n","    torch.save(generator1, \"saved_models/\"+str(name)+\"_G_Monet2Picture.pt\")\n","    torch.save(generator2, \"saved_models/\"+str(name)+\"_G_Picture2Monet.pt\")\n","    torch.save(discriminator1, \"saved_models/\"+str(name)+\"_D_Monet.pt\")\n","    torch.save(discriminator2, \"saved_models/\"+str(name)+\"_D_Picture.pt\")\n","\n","def load_models(name):\n","    G_Monet2Picture=torch.load(\"saved_models/\"+str(name)+\"_G_Monet2Picture.pt\")\n","    G_Picture2Monet=torch.load(\"saved_models/\"+str(name)+\"_G_Picture2Monet.pt\")\n","    D_Monet=torch.load(\"saved_models/\"+str(name)+\"_D_Monet.pt\")\n","    D_Picture=torch.load(\"saved_models/\"+str(name)+\"_D_Picture.pt\")\n","    return G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture"],"metadata":{"id":"dHisSm_I58EH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Test/Plot"],"metadata":{"id":"6iDKuuSW59l3"}},{"cell_type":"code","source":["#asdf\n","def plot_images_test(dataloader_monet_test, dataloader_picture_test):\n","    batch_a_test = next(iter(dataloader_monet_test))[0].cuda()\n","    real_a_test = batch_a_test.cpu().detach()\n","    fake_b_test = G_Monet2Picture(batch_a_test ).cpu().detach()\n","\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(np.transpose(vutils.make_grid((real_a_test[:4]+1)/2,\n","                                              padding=2, normalize=True).cpu(),(1,2,0)))\n","    plt.axis(\"off\")\n","    plt.title(\"Real Monets\")\n","    plt.show()\n","\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(np.transpose(vutils.make_grid((fake_b_test[:4]+1)/2,\n","                                              padding=2, normalize=True).cpu(),(1,2,0)))\n","    plt.axis(\"off\")\n","    plt.title(\"Generated Pictures\")\n","    plt.show()\n","\n","    batch_b_test = next(iter(dataloader_picture_test))[0].cuda()\n","    real_b_test = batch_b_test.cpu().detach()\n","    fake_a_test = G_Picture2Monet(batch_b_test ).cpu().detach()\n","\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(np.transpose(vutils.make_grid((real_b_test[:4]+1)/2,\n","                                              padding=2, normalize=True).cpu(),(1,2,0)))\n","    plt.axis(\"off\")\n","    plt.title(\"Real Pictures\")\n","    plt.show()\n","\n","    plt.figure(figsize=(10,10))\n","    plt.imshow(np.transpose(vutils.make_grid((fake_a_test[:4]+1)/2,\n","                                              padding=2, normalize=True).cpu(),(1,2,0)))\n","    plt.axis(\"off\")\n","    plt.title(\"Generated Monets\")\n","    plt.show()"],"metadata":{"id":"tPFQOp1E6AuY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Execution"],"metadata":{"id":"2WM5JX-F6gOd"}},{"cell_type":"code","source":["lr = 0.0002\n","beta1 = 0.5"],"metadata":{"id":"TSABr5Fy6h47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#IF STARTING TRAINING OVER:\n","#Initialize generators and discriminators, if there are no models to build off of\n","G_Monet2Picture = Generator()\n","G_Picture2Monet = Generator()\n","D_Monet = Discriminator()\n","D_Picture = Discriminator()"],"metadata":{"id":"yLQ2fu7y3rnF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##OR load generators and discriminators from models that this notebook has generated before.\n","G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture = load_models(\"newest\")\n","#\"newest\" or \"N\" where N = 15, 25, 35, 45, 50, etc. based on number of epochs before"],"metadata":{"id":"FpD4NA6D39FY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# temp cell\n","G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture = load_models(\"63\")"],"metadata":{"id":"64Llm0NkD8hY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#This is one plus how much many full epochs have trained so far (i.e., the next epoch to train)\n","start_epoch = 64"],"metadata":{"id":"o_2XcOX5391h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize optimizers\n","optimizer_G_Monet2Picture = torch.optim.Adam(G_Monet2Picture.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizer_G_Picture2Monet = torch.optim.Adam(G_Picture2Monet.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizer_D_Monet = torch.optim.Adam(D_Monet.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizer_D_Picture = torch.optim.Adam(D_Picture.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","# Run training\n","Losses_Across_Epochs = train(dataloader_picture_train, dataloader_monet_train,\n","      dataloader_picture_test, dataloader_monet_test,\n","      G_Monet2Picture, G_Picture2Monet, D_Monet, D_Picture, optimizer_D_Monet, optimizer_D_Picture,\n","      optimizer_G_Monet2Picture, optimizer_G_Picture2Monet, start_epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1usUXy9RFRKWeNgAHZeUVx1Dw2Kx1Vtne"},"id":"L-dTUIPA4BuR","executionInfo":{"status":"error","timestamp":1660357579252,"user_tz":300,"elapsed":2845885,"user":{"displayName":"John Li","userId":"07983087676873063182"}},"outputId":"410ecc6a-1d02-4835-bec5-06ba5b70858d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}